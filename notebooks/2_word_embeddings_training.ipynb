{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "07df2032",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ca247da6-4b6c-4dc6-887d-ec236ecba442",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict, Counter\n",
    "from dotenv import load_dotenv\n",
    "from gensim.models import FastText\n",
    "from gensim.utils import simple_preprocess\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "import multiprocessing\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import re\n",
    "import sys\n",
    "from sklearn.manifold import TSNE\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "39307d43",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this is needed, cause notebooks not on same level as helpers\n",
    "sys.path.insert(0, os.path.abspath(\"..\"))  # assumes notebook is in {root}/notebooks/{fname}.ipynb\n",
    "\n",
    "# autoreload imports within same session when rerunning cell\n",
    "%load_ext autoreload\n",
    "\n",
    "%autoreload 2\n",
    "from helpers.data_fetchers import fetch_sl_stopwords\n",
    "from helpers.nlp import read_corpus, \\\n",
    "        get_similar_words_fasttext, \\\n",
    "        get_topn_neighbors, jaccard, \\\n",
    "        generate_seed_words_from_stem, \\\n",
    "        fasttext_incr_train_and_predict, \\\n",
    "        compute_epochwise_jaccard_similarity"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "178124b6-29fc-4011-a7ee-7a4b788f5dec",
   "metadata": {},
   "source": [
    "## Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8217d38d-8fa9-47bf-bf52-41d48a4236e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "\n",
    "CORPUS_INDEX_ID = os.getenv(\"CORPUS_INDEX_ID\")\n",
    "CORPUS_INDEX_SHEET = os.getenv(\"CORPUS_INDEX_SHEET\")\n",
    "ORIG_CORPUS_DIR = os.getenv(\"ORIG_CORPUS_DIR\")\n",
    "LEMMA_CORPUS_DIR = os.getenv(\"LEMMATIZED_CORPUS_DIR\")\n",
    "NUM_CPUS = multiprocessing.cpu_count()\n",
    "\n",
    "# correct constants for calling within notebook\n",
    "MAIN_ORIGINAL = '../' + ORIG_CORPUS_DIR + 'sentence'\n",
    "MAIN_LEMMA = '../' + LEMMA_CORPUS_DIR + 'sentence'\n",
    "PAR_ORG = '../' + ORIG_CORPUS_DIR + 'paragraph'\n",
    "PAR_LEM = '../' + LEMMA_CORPUS_DIR + 'paragraph'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d4335f8-52af-4ca3-9b44-8603748d2e76",
   "metadata": {},
   "source": [
    "## Data prep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ab685499-531c-4bde-b62a-c0687efbd78f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>shame_id</th>\n",
       "      <th>author_and_title</th>\n",
       "      <th>original_id</th>\n",
       "      <th>author</th>\n",
       "      <th>author_fname</th>\n",
       "      <th>author_lname</th>\n",
       "      <th>author_gender</th>\n",
       "      <th>title</th>\n",
       "      <th>word_count</th>\n",
       "      <th>publ_year</th>\n",
       "      <th>publ_year_clean</th>\n",
       "      <th>doc_link</th>\n",
       "      <th>source_corpus</th>\n",
       "      <th>comment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SHAME_1</td>\n",
       "      <td>Albin Prepeluh-Mina</td>\n",
       "      <td>KDSP199</td>\n",
       "      <td>Albin Prepeluh</td>\n",
       "      <td>Albin</td>\n",
       "      <td>Prepeluh</td>\n",
       "      <td>M</td>\n",
       "      <td>Mina</td>\n",
       "      <td>33063</td>\n",
       "      <td>1910.0</td>\n",
       "      <td>1910.0</td>\n",
       "      <td>https://github.com/COST-ELTeC/ELTeC-slv/blob/v...</td>\n",
       "      <td>KDSP</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SHAME_2</td>\n",
       "      <td>Alojz Kraigher-Kontrolor Å krobar</td>\n",
       "      <td>KDSP234</td>\n",
       "      <td>Alojz Kraigher</td>\n",
       "      <td>Alojz</td>\n",
       "      <td>Kraigher</td>\n",
       "      <td>M</td>\n",
       "      <td>Kontrolor Å krobar</td>\n",
       "      <td>130090</td>\n",
       "      <td>1914.0</td>\n",
       "      <td>1914.0</td>\n",
       "      <td>https://www.dlib.si/details/URN:NBN:SI:DOC-KCB...</td>\n",
       "      <td>KDSP</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>SHAME_3</td>\n",
       "      <td>Alojz Kraigher-Mlada ljubezen</td>\n",
       "      <td>KDSP254</td>\n",
       "      <td>Alojz Kraigher</td>\n",
       "      <td>Alojz</td>\n",
       "      <td>Kraigher</td>\n",
       "      <td>M</td>\n",
       "      <td>Mlada ljubezen</td>\n",
       "      <td>75260</td>\n",
       "      <td>1917.0</td>\n",
       "      <td>1917.0</td>\n",
       "      <td>https://github.com/COST-ELTeC/ELTeC-slv/blob/v...</td>\n",
       "      <td>KDSP</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>SHAME_4</td>\n",
       "      <td>Alojz Kraigher-Peter Drozeg</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Alojz Kraigher</td>\n",
       "      <td>Alojz</td>\n",
       "      <td>Kraigher</td>\n",
       "      <td>M</td>\n",
       "      <td>Peter Drozeg</td>\n",
       "      <td>20324</td>\n",
       "      <td>1916.0</td>\n",
       "      <td>1916.0</td>\n",
       "      <td>https://lit.ijs.si/kraigher.html</td>\n",
       "      <td>Wikivir - leposlovje</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>SHAME_5</td>\n",
       "      <td>Alojzij Kokalj-Cerkvene miÅ¡i</td>\n",
       "      <td>KDSP227</td>\n",
       "      <td>Alojzij Kokalj</td>\n",
       "      <td>Alojzij</td>\n",
       "      <td>Kokalj</td>\n",
       "      <td>M</td>\n",
       "      <td>Cerkvene miÅ¡i</td>\n",
       "      <td>86058</td>\n",
       "      <td>1913.0</td>\n",
       "      <td>1913.0</td>\n",
       "      <td>https://sl.wikisource.org/wiki/Cerkvene_mi%C5%A1i</td>\n",
       "      <td>KDSP</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  shame_id                  author_and_title original_id          author  \\\n",
       "0  SHAME_1               Albin Prepeluh-Mina     KDSP199  Albin Prepeluh   \n",
       "1  SHAME_2  Alojz Kraigher-Kontrolor Å krobar     KDSP234  Alojz Kraigher   \n",
       "2  SHAME_3     Alojz Kraigher-Mlada ljubezen     KDSP254  Alojz Kraigher   \n",
       "3  SHAME_4       Alojz Kraigher-Peter Drozeg         NaN  Alojz Kraigher   \n",
       "4  SHAME_5      Alojzij Kokalj-Cerkvene miÅ¡i     KDSP227  Alojzij Kokalj   \n",
       "\n",
       "  author_fname author_lname author_gender              title  word_count  \\\n",
       "0        Albin     Prepeluh             M               Mina       33063   \n",
       "1        Alojz     Kraigher             M  Kontrolor Å krobar      130090   \n",
       "2        Alojz     Kraigher             M     Mlada ljubezen       75260   \n",
       "3        Alojz     Kraigher             M       Peter Drozeg       20324   \n",
       "4      Alojzij       Kokalj             M      Cerkvene miÅ¡i       86058   \n",
       "\n",
       "   publ_year  publ_year_clean  \\\n",
       "0     1910.0           1910.0   \n",
       "1     1914.0           1914.0   \n",
       "2     1917.0           1917.0   \n",
       "3     1916.0           1916.0   \n",
       "4     1913.0           1913.0   \n",
       "\n",
       "                                            doc_link         source_corpus  \\\n",
       "0  https://github.com/COST-ELTeC/ELTeC-slv/blob/v...                  KDSP   \n",
       "1  https://www.dlib.si/details/URN:NBN:SI:DOC-KCB...                  KDSP   \n",
       "2  https://github.com/COST-ELTeC/ELTeC-slv/blob/v...                  KDSP   \n",
       "3                  https://lit.ijs.si/kraigher.html   Wikivir - leposlovje   \n",
       "4  https://sl.wikisource.org/wiki/Cerkvene_mi%C5%A1i                  KDSP   \n",
       "\n",
       "  comment  \n",
       "0     NaN  \n",
       "1     NaN  \n",
       "2     NaN  \n",
       "3     NaN  \n",
       "4     NaN  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('../corpus_metadata.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5fcc872-7dcb-4b74-8218-7e3c820efaa9",
   "metadata": {},
   "source": [
    "## One-time FastText training to see results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2985c038-4611-42db-91e8-b344a7d08bf1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(913948, 862173)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert generator to list for training (if your corpus is not huge)\n",
    "sentences_orig = list(read_corpus(MAIN_ORIGINAL))\n",
    "sentences_lemma = list(read_corpus(MAIN_LEMMA))\n",
    "\n",
    "# different num of sentences, cause Wikivir wasn't lemmatized\n",
    "len(sentences_orig), len(sentences_lemma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a4bf2ba1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a list of seed words based on the root lemma \"sram\" to be used\n",
    "# in training\n",
    "flat_words = [word for sent in sentences_lemma for word in sent]\n",
    "word_counts = Counter(flat_words)\n",
    "matches = [w for w in word_counts if 'sram' in w]  # crude stem match\n",
    "\n",
    "# manually inspected the list below and generated the excluded words\n",
    "non_shame_words = ['nesramnost', 'narnesramen', 'nasramen', 'nesramen',\n",
    "                   'nesramno']\n",
    "\n",
    "seed_words = []\n",
    "for m in sorted(matches): \n",
    "    if m not in non_shame_words:\n",
    "        # uncomment to print\n",
    "        #print(m)\n",
    "        seed_words.append(m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "96276d5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sram 1279\n",
      "sramota 1236\n",
      "sramovati 695\n",
      "sramoten 246\n",
      "sramezljivo 228\n",
      "osramocen 162\n",
      "sramezljivost 139\n",
      "sramezljiv 120\n",
      "sramotno 102\n",
      "osramotiti 99\n",
      "nesramnez 76\n",
      "sramotiti 69\n",
      "zasramovati 57\n",
      "sramozljivost 32\n",
      "nesramnica 28\n",
      "zasramovanje 26\n",
      "osramocenje 24\n",
      "sramotilen 19\n",
      "sramotenje 12\n",
      "sramozljiv 12\n",
      "sramovanje 8\n",
      "sramu 8\n",
      "zasramovan 8\n",
      "sramujoc 7\n",
      "brezsramno 5\n",
      "osramoten 5\n",
      "sramocenje 5\n",
      "zasramovalec 5\n",
      "brezsramen 4\n",
      "sramotilec 4\n",
      "sramozljivo 4\n",
      "nesramozljiv 3\n",
      "osramocenost 3\n",
      "presramoten 3\n",
      "sramocen 3\n",
      "zasramljivo 3\n",
      "brezsramnik 2\n",
      "nesramnezev 2\n",
      "nesramnik 2\n",
      "osramljen 2\n",
      "osramotjen 2\n",
      "presramotno 2\n",
      "sramez 2\n",
      "sramot 2\n",
      "sramote 2\n",
      "sramotec 2\n",
      "sramovaje 2\n",
      "zasramba 2\n",
      "zasramovalen 2\n",
      "krvosramen 1\n",
      "krvosramstvo 1\n",
      "nesramezljivo 1\n",
      "nesramezljivost 1\n",
      "nesramnej 1\n",
      "nesramnes 1\n",
      "nesramnosla 1\n",
      "nesramoten 1\n",
      "osramocenov 1\n",
      "osramocevati 1\n",
      "osramotenje 1\n",
      "osramoteti 1\n",
      "osramotivsiti 1\n",
      "osramovati 1\n",
      "presramezljiv 1\n",
      "presramozljiv 1\n",
      "sramec 1\n",
      "sramezjiv 1\n",
      "sramiti 1\n",
      "sramoti 1\n",
      "sramotilka 1\n",
      "sramotivec 1\n",
      "sramotljiv 1\n",
      "sramuje 1\n",
      "sramvati 1\n",
      "zasramljiv 1\n",
      "zasramnji 1\n",
      "zasramujoc 1\n",
      "zasramvan 1\n"
     ]
    }
   ],
   "source": [
    "# check how often seed words appear in lemma\n",
    "flat_words = [word for sent in sentences_lemma for word in sent]\n",
    "word_counts = Counter(flat_words)\n",
    "\n",
    "# Create a list of tuples: (word, count)\n",
    "seed_counts = [(w, word_counts.get(w, 0)) for w in seed_words]\n",
    "\n",
    "# Sort by count (descending)\n",
    "seed_counts_sorted = sorted(seed_counts, key=lambda x: x[1], reverse=True)\n",
    "\n",
    "for w, count in seed_counts_sorted:\n",
    "    print(w, count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c484db48",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['sram',\n",
       " 'sramota',\n",
       " 'sramovati',\n",
       " 'sramoten',\n",
       " 'sramezljivo',\n",
       " 'osramocen',\n",
       " 'sramezljivost',\n",
       " 'sramezljiv',\n",
       " 'sramotno',\n",
       " 'osramotiti',\n",
       " 'nesramnez',\n",
       " 'sramotiti',\n",
       " 'zasramovati']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Filter counts to only seed words with more than 50 appearances\n",
    "common_seed_words = [w for w, c in seed_counts_sorted if c >= 50]\n",
    "\n",
    "common_seed_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c0f1da60",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['sram',\n",
       " 'sramota',\n",
       " 'sramovati',\n",
       " 'sramoten',\n",
       " 'sramezljivo',\n",
       " 'sramezljivost',\n",
       " 'sramezljiv',\n",
       " 'sramotno',\n",
       " 'sramotiti']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# use help funct for seed words, made after teh analysis above\n",
    "sw_loc = '../output/seed_words.txt'\n",
    "seed_words = generate_seed_words_from_stem(\n",
    "    stem=\"sram\", corpus_path=\"../data/lemma_txt_corpus/sentence\",\n",
    "    n=50, out_path=sw_loc)\n",
    "\n",
    "seed_words = [x for x, _ in seed_words]\n",
    "seed_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "20a8ad3d-54b2-45d3-85d0-ca8a5cdd689f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train FastText embeddings\n",
    "model = FastText(\n",
    "    sentences=sentences_lemma,\n",
    "    vector_size=300,   # embedding size\n",
    "    window=5,\n",
    "    min_count=1,\n",
    "    workers=NUM_CPUS,\n",
    "    sg=1,              # 1 = skip-gram; better for semantic similarity\n",
    "    epochs=5\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e7b9072b-68cc-40fd-9615-fb3c1048b9b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>seed</th>\n",
       "      <th>similar</th>\n",
       "      <th>similarity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>sram</td>\n",
       "      <td>sramu</td>\n",
       "      <td>0.903356</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>sram</td>\n",
       "      <td>sramuje</td>\n",
       "      <td>0.845076</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>sram</td>\n",
       "      <td>sramec</td>\n",
       "      <td>0.807120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>sram</td>\n",
       "      <td>sramez</td>\n",
       "      <td>0.770276</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>sram</td>\n",
       "      <td>sramovaje</td>\n",
       "      <td>0.761542</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>895</th>\n",
       "      <td>sramotiti</td>\n",
       "      <td>obuzdati</td>\n",
       "      <td>0.691205</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>896</th>\n",
       "      <td>sramotiti</td>\n",
       "      <td>zmesiti</td>\n",
       "      <td>0.691000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>897</th>\n",
       "      <td>sramotiti</td>\n",
       "      <td>prevarati</td>\n",
       "      <td>0.689994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>898</th>\n",
       "      <td>sramotiti</td>\n",
       "      <td>zastrahovati</td>\n",
       "      <td>0.689864</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>899</th>\n",
       "      <td>sramotiti</td>\n",
       "      <td>umeknztiti</td>\n",
       "      <td>0.689785</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>900 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          seed       similar  similarity\n",
       "0         sram         sramu    0.903356\n",
       "1         sram       sramuje    0.845076\n",
       "2         sram        sramec    0.807120\n",
       "3         sram        sramez    0.770276\n",
       "4         sram     sramovaje    0.761542\n",
       "..         ...           ...         ...\n",
       "895  sramotiti      obuzdati    0.691205\n",
       "896  sramotiti       zmesiti    0.691000\n",
       "897  sramotiti     prevarati    0.689994\n",
       "898  sramotiti  zastrahovati    0.689864\n",
       "899  sramotiti    umeknztiti    0.689785\n",
       "\n",
       "[900 rows x 3 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# find similar words\n",
    "similarity_data = get_similar_words_fasttext(model, seed_words, topn=100)\n",
    "\n",
    "df_sim_words = pd.DataFrame(similarity_data)\n",
    "#pd.set_option('display.max_rows', None)\n",
    "pd.reset_option('^display.', silent=True)\n",
    "\n",
    "df_sim_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "93bfcdb2-6bc2-44cf-805b-52260b47e4fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save similar words\n",
    "os.makedirs(\"../output\", exist_ok=True)\n",
    "df_sim_words.to_csv(\"../output/shame_similar_words.csv\", index=False)\n",
    "\n",
    "# save model\n",
    "os.makedirs(\"../models\", exist_ok=True)\n",
    "model.save(\"../models/fasttext_lemma_5ep.model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7ac5b3f",
   "metadata": {},
   "source": [
    "## Continuously train for n epochs > predict at each epoch batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2788d39b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Loading existing model from: ../models/ft_word_embeddings/ft_300ep_lemma_txt_sentence_remove_stopwords.model\n",
      "âœ… Jaccard similarity CSV saved to: ../output/ft_word_embeddings/ep_jaccard_sim_lemma_txt_sentence_remove_stopwords.csv\n",
      "âœ… Loading existing model from: ../models/ft_word_embeddings/ft_300ep_original_txt_sentence_remove_stopwords.model\n",
      "âœ… Jaccard similarity CSV saved to: ../output/ft_word_embeddings/ep_jaccard_sim_original_txt_sentence_remove_stopwords.csv\n",
      "âœ… Loading existing model from: ../models/ft_word_embeddings/ft_300ep_lemma_txt_sentence_keep_stopwords.model\n",
      "âœ… Jaccard similarity CSV saved to: ../output/ft_word_embeddings/ep_jaccard_sim_lemma_txt_sentence_keep_stopwords.csv\n",
      "âœ… Loading existing model from: ../models/ft_word_embeddings/ft_300ep_original_txt_sentence_keep_stopwords.model\n",
      "âœ… Jaccard similarity CSV saved to: ../output/ft_word_embeddings/ep_jaccard_sim_original_txt_sentence_keep_stopwords.csv\n",
      "âœ… Loading existing model from: ../models/ft_word_embeddings/ft_300ep_lemma_txt_paragraph_remove_stopwords.model\n",
      "âœ… Jaccard similarity CSV saved to: ../output/ft_word_embeddings/ep_jaccard_sim_lemma_txt_paragraph_remove_stopwords.csv\n",
      "âœ… Loading existing model from: ../models/ft_word_embeddings/ft_300ep_original_txt_paragraph_remove_stopwords.model\n",
      "âœ… Jaccard similarity CSV saved to: ../output/ft_word_embeddings/ep_jaccard_sim_original_txt_paragraph_remove_stopwords.csv\n",
      "âœ… Loading existing model from: ../models/ft_word_embeddings/ft_300ep_lemma_txt_paragraph_keep_stopwords.model\n",
      "âœ… Jaccard similarity CSV saved to: ../output/ft_word_embeddings/ep_jaccard_sim_lemma_txt_paragraph_keep_stopwords.csv\n",
      "âœ… Loading existing model from: ../models/ft_word_embeddings/ft_300ep_original_txt_paragraph_keep_stopwords.model\n",
      "âœ… Jaccard similarity CSV saved to: ../output/ft_word_embeddings/ep_jaccard_sim_original_txt_paragraph_keep_stopwords.csv\n"
     ]
    }
   ],
   "source": [
    "# â”€â”€â”€ Configuration â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "stopwords = fetch_sl_stopwords('../data/stopwords_sl.txt')\n",
    "st_treatment = {'remove_stopwords': stopwords, 'keep_stopwords': None}\n",
    "step_epochs = 5\n",
    "max_epochs = 300\n",
    "topn = 100\n",
    "NUM_CPUS = multiprocessing.cpu_count()\n",
    "\n",
    "# â”€â”€â”€ Prepare Corpus â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "\n",
    "#sentences_orig = list(read_corpus(MAIN_ORIGINAL, stopwords))\n",
    "#sentences_lemma = list(read_corpus(MAIN_LEMMA, stopwords))\n",
    "\n",
    "# â”€â”€â”€ Train FastText model â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "\n",
    "model_name = \"ft_300ep_\"\n",
    "model_dir = \"../models/ft_word_embeddings\"\n",
    "\n",
    "# compute all possibilities:\n",
    "for granularity in ['sentence', 'paragraph']:\n",
    "    for st_choice in st_treatment.keys():\n",
    "        for content_type in ['lemma_txt', 'original_txt']:\n",
    "            model_name = f\"ft_300ep_{content_type}_{granularity}_{st_choice}\"\n",
    "            model_path = os.path.join(model_dir, model_name+'.model')\n",
    "            _stopwords = st_treatment[st_choice]\n",
    "            input_dir = f'../data/{content_type}_corpus/{granularity}'\n",
    "            output_json_dir = '../output/ft_word_embeddings/'\n",
    "            output_json_fname = f\"neighbors_by_epoch_ft_300ep_{content_type}_{granularity}_{st_choice}.json\"\n",
    "            output_json_path = os.path.join(output_json_dir, output_json_fname)\n",
    "\n",
    "\n",
    "            if os.path.exists(model_path):\n",
    "                print(f\"âœ… Loading existing model from: {model_path}\")\n",
    "                ft_model = FastText.load(model_path)\n",
    "            else:\n",
    "                print(f\"ðŸš€ Model not found at {model_path}, training new one...\")\n",
    "\n",
    "                sentences = list(read_corpus(input_dir, _stopwords))\n",
    "                \n",
    "                ft_model = fasttext_incr_train_and_predict(\n",
    "                    sentences=sentences,\n",
    "                    seed_words=seed_words,\n",
    "                    output_json_fname=output_json_fname,\n",
    "                    output_json_dir=output_json_dir,\n",
    "                    output_model_fname=model_name,\n",
    "                    output_model_dir=model_dir,\n",
    "                    workers=NUM_CPUS,\n",
    "                    max_epochs=max_epochs,\n",
    "                    step_epochs=step_epochs,\n",
    "                    topn=topn\n",
    "                    )\n",
    "            \n",
    "            # compute stability in mean Jaccardian similarity between consecutive epochs\n",
    "            stability_df = compute_epochwise_jaccard_similarity(\n",
    "                neighbor_json_path=output_json_path,\n",
    "                seed_words=seed_words,\n",
    "                output_csv_path=f\"../output/ft_word_embeddings/ep_jaccard_sim_{content_type}_{granularity}_{st_choice}.csv\"\n",
    "            )\n",
    "\n",
    "            # save plot for visual inspection\n",
    "            plt.figure()\n",
    "            plt.plot(stability_df[\"curr_epoch\"], \n",
    "                     stability_df[\"mean_jaccard\"], \n",
    "                     marker='o')\n",
    "            plt.suptitle(\"Mean Jaccard Between Adjacent FastText Epochs\")\n",
    "            plt.title(f\"Content: {content_type}, Granularity: {granularity}, Stopwords: {st_choice.split('_')[0]}\")\n",
    "            plt.xlabel(\"Epoch (current)\")\n",
    "            plt.ylabel(\"Mean Jaccard vs previous\")\n",
    "            plt.grid(True)\n",
    "            plt.ylim(0, 1)\n",
    "            plt.savefig(f\"../output/ft_word_embeddings/jaccard_curve_ft_{content_type}_{granularity}_{st_choice}.png\")\n",
    "            plt.close()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9e94423d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prev_epoch</th>\n",
       "      <th>curr_epoch</th>\n",
       "      <th>mean_jaccard</th>\n",
       "      <th>median_jaccard</th>\n",
       "      <th>txt_type</th>\n",
       "      <th>granularity</th>\n",
       "      <th>stopwords</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "      <td>0.623717</td>\n",
       "      <td>0.612903</td>\n",
       "      <td>original</td>\n",
       "      <td>sentence</td>\n",
       "      <td>keep</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10</td>\n",
       "      <td>15</td>\n",
       "      <td>0.774270</td>\n",
       "      <td>0.785714</td>\n",
       "      <td>original</td>\n",
       "      <td>sentence</td>\n",
       "      <td>keep</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>15</td>\n",
       "      <td>20</td>\n",
       "      <td>0.822708</td>\n",
       "      <td>0.834862</td>\n",
       "      <td>original</td>\n",
       "      <td>sentence</td>\n",
       "      <td>keep</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>20</td>\n",
       "      <td>25</td>\n",
       "      <td>0.841557</td>\n",
       "      <td>0.851852</td>\n",
       "      <td>original</td>\n",
       "      <td>sentence</td>\n",
       "      <td>keep</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>25</td>\n",
       "      <td>30</td>\n",
       "      <td>0.791251</td>\n",
       "      <td>0.801802</td>\n",
       "      <td>original</td>\n",
       "      <td>sentence</td>\n",
       "      <td>keep</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>467</th>\n",
       "      <td>275</td>\n",
       "      <td>280</td>\n",
       "      <td>0.695754</td>\n",
       "      <td>0.724138</td>\n",
       "      <td>lemma</td>\n",
       "      <td>paragraph</td>\n",
       "      <td>keep</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>468</th>\n",
       "      <td>280</td>\n",
       "      <td>285</td>\n",
       "      <td>0.684722</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>lemma</td>\n",
       "      <td>paragraph</td>\n",
       "      <td>keep</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>469</th>\n",
       "      <td>285</td>\n",
       "      <td>290</td>\n",
       "      <td>0.679521</td>\n",
       "      <td>0.652893</td>\n",
       "      <td>lemma</td>\n",
       "      <td>paragraph</td>\n",
       "      <td>keep</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>470</th>\n",
       "      <td>290</td>\n",
       "      <td>295</td>\n",
       "      <td>0.701762</td>\n",
       "      <td>0.694915</td>\n",
       "      <td>lemma</td>\n",
       "      <td>paragraph</td>\n",
       "      <td>keep</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>471</th>\n",
       "      <td>295</td>\n",
       "      <td>300</td>\n",
       "      <td>0.678501</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>lemma</td>\n",
       "      <td>paragraph</td>\n",
       "      <td>keep</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>472 rows Ã— 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     prev_epoch  curr_epoch  mean_jaccard  median_jaccard  txt_type  \\\n",
       "0             5          10      0.623717        0.612903  original   \n",
       "1            10          15      0.774270        0.785714  original   \n",
       "2            15          20      0.822708        0.834862  original   \n",
       "3            20          25      0.841557        0.851852  original   \n",
       "4            25          30      0.791251        0.801802  original   \n",
       "..          ...         ...           ...             ...       ...   \n",
       "467         275         280      0.695754        0.724138     lemma   \n",
       "468         280         285      0.684722        0.666667     lemma   \n",
       "469         285         290      0.679521        0.652893     lemma   \n",
       "470         290         295      0.701762        0.694915     lemma   \n",
       "471         295         300      0.678501        0.666667     lemma   \n",
       "\n",
       "    granularity stopwords  \n",
       "0      sentence      keep  \n",
       "1      sentence      keep  \n",
       "2      sentence      keep  \n",
       "3      sentence      keep  \n",
       "4      sentence      keep  \n",
       "..          ...       ...  \n",
       "467   paragraph      keep  \n",
       "468   paragraph      keep  \n",
       "469   paragraph      keep  \n",
       "470   paragraph      keep  \n",
       "471   paragraph      keep  \n",
       "\n",
       "[472 rows x 7 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Join all stability csv's into one, so we can use it for streamlit:\n",
    "def join_jaccard_csvs_to_df(directory=\"../output/ft_word_embeddings\"):\n",
    "    all_dfs = []\n",
    "    # Regex to capture the three config parts from filename\n",
    "    pattern = re.compile(r\"ep_jaccard_sim_([^_]+_[^_]+)_([^_]+)_(remove_stopwords|keep_stopwords)\\.csv\")\n",
    "    \n",
    "    for fname in os.listdir(directory):\n",
    "        match = pattern.match(fname)\n",
    "        if match:\n",
    "            content_type, granularity, st_choice = match.groups()\n",
    "            df = pd.read_csv(os.path.join(directory, fname))\n",
    "            # Attach config columns\n",
    "            df[\"txt_type\"] = content_type.split('_')[0]\n",
    "            df[\"granularity\"] = granularity\n",
    "            df[\"stopwords\"] = st_choice.split('_')[0]\n",
    "            all_dfs.append(df)\n",
    "    # Combine all into one DataFrame\n",
    "    big_df = pd.concat(all_dfs, ignore_index=True)\n",
    "    return big_df\n",
    "\n",
    "# Usage:\n",
    "all_jaccard = join_jaccard_csvs_to_df()\n",
    "all_jaccard.to_csv(\"../output/all_jaccard_epochs.csv\", index=False)\n",
    "all_jaccard.to_csv(\"../streamlit_app/data/all_jaccard_ft_epochs.csv\", index=False)\n",
    "all_jaccard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc78960c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "3.11.9",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
