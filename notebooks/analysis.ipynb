{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "27e0e441",
   "metadata": {},
   "source": [
    "Check the avg sentence length of the corpus to be fed to FastText, to make sure the window size makes sense (or we need to buffer 2-3 sentences together)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4dfe397e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from gensim.utils import simple_preprocess\n",
    "import sys\n",
    "from tqdm import tqdm\n",
    "\n",
    "# autoreload imports within same session when rerunning cell\n",
    "%load_ext autoreload\n",
    "\n",
    "%autoreload 2\n",
    "# this is needed, cause notebooks not on same level as helpers\n",
    "sys.path.insert(0, os.path.abspath(\"..\"))  # assumes notebook is in {root}/notebooks/{fname}.ipynb\n",
    "from helpers.data_fetchers import fetch_sl_stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "26cc2fec",
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords = fetch_sl_stopwords('../data/stopwords_sl.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "89b228a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_sentence_length_stats_np(directory, stopwords=None):\n",
    "    \"\"\"\n",
    "    Computes mean and std of sentence lengths per text file using numpy.\n",
    "    \n",
    "    Args:\n",
    "        directory (str): Path to directory with `.txt` files.\n",
    "        stopwords (set, optional): Stopwords to remove.\n",
    "        \n",
    "    Returns:\n",
    "        pd.DataFrame: Columns = txt_name, num_sentences, avg_sent_length, std_length\n",
    "    \"\"\"\n",
    "    if stopwords:\n",
    "        stopwords = set(simple_preprocess(' '.join(stopwords), deacc=True))\n",
    "\n",
    "    data = []\n",
    "    \n",
    "    for filename in tqdm(os.listdir(directory)):\n",
    "        if filename.endswith('.txt'):\n",
    "            filepath = os.path.join(directory, filename)\n",
    "            sentence_lengths = []\n",
    "            \n",
    "            with open(filepath, 'r', encoding='utf-8') as file:\n",
    "                for line in file:\n",
    "                    tokens = simple_preprocess(line, deacc=True)\n",
    "                    if stopwords:\n",
    "                        tokens = [w for w in tokens if w not in stopwords]\n",
    "                    if tokens:  # Only count non-empty sentences\n",
    "                        sentence_lengths.append(len(tokens))\n",
    "            \n",
    "            if sentence_lengths:\n",
    "                avg_len = np.mean(sentence_lengths)\n",
    "                std_len = np.std(sentence_lengths, ddof=1) if len(sentence_lengths) > 1 else 0\n",
    "                num_sent = len(sentence_lengths)\n",
    "            else:\n",
    "                avg_len, std_len, num_sent = 0, 0, 0\n",
    "\n",
    "            if 'paragraph' in directory:\n",
    "                unit = 'paragraph'\n",
    "            elif 'sentence' in directory:\n",
    "                unit = 'sentence'\n",
    "            else:\n",
    "                unit = 'x'\n",
    "            \n",
    "            data.append({\n",
    "                \"txt_name\": filename,\n",
    "                f\"num_{unit}s\": num_sent,\n",
    "                f\"avg_{unit}_length\": avg_len,\n",
    "                \"std_length\": std_len\n",
    "            })\n",
    "            \n",
    "    df = pd.DataFrame(data)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "40204f65",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 281/281 [00:18<00:00, 15.00it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>txt_name</th>\n",
       "      <th>num_sentences</th>\n",
       "      <th>avg_sentence_length</th>\n",
       "      <th>std_length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SHAME_92.txt</td>\n",
       "      <td>2024</td>\n",
       "      <td>6.180336</td>\n",
       "      <td>5.185019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SHAME_242.txt</td>\n",
       "      <td>2458</td>\n",
       "      <td>6.723352</td>\n",
       "      <td>4.719390</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>SHAME_136.txt</td>\n",
       "      <td>3605</td>\n",
       "      <td>6.893481</td>\n",
       "      <td>4.589688</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>SHAME_204.txt</td>\n",
       "      <td>2975</td>\n",
       "      <td>6.128403</td>\n",
       "      <td>3.977363</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>SHAME_108.txt</td>\n",
       "      <td>1490</td>\n",
       "      <td>7.095973</td>\n",
       "      <td>5.239161</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>276</th>\n",
       "      <td>SHAME_207.txt</td>\n",
       "      <td>1030</td>\n",
       "      <td>9.834951</td>\n",
       "      <td>5.957571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>277</th>\n",
       "      <td>SHAME_40.txt</td>\n",
       "      <td>4800</td>\n",
       "      <td>5.699375</td>\n",
       "      <td>4.302512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>278</th>\n",
       "      <td>SHAME_264.txt</td>\n",
       "      <td>2033</td>\n",
       "      <td>6.555337</td>\n",
       "      <td>4.156275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>279</th>\n",
       "      <td>SHAME_27.txt</td>\n",
       "      <td>5444</td>\n",
       "      <td>6.767818</td>\n",
       "      <td>4.882385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>280</th>\n",
       "      <td>SHAME_236.txt</td>\n",
       "      <td>4908</td>\n",
       "      <td>6.115322</td>\n",
       "      <td>4.781143</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>281 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          txt_name  num_sentences  avg_sentence_length  std_length\n",
       "0     SHAME_92.txt           2024             6.180336    5.185019\n",
       "1    SHAME_242.txt           2458             6.723352    4.719390\n",
       "2    SHAME_136.txt           3605             6.893481    4.589688\n",
       "3    SHAME_204.txt           2975             6.128403    3.977363\n",
       "4    SHAME_108.txt           1490             7.095973    5.239161\n",
       "..             ...            ...                  ...         ...\n",
       "276  SHAME_207.txt           1030             9.834951    5.957571\n",
       "277   SHAME_40.txt           4800             5.699375    4.302512\n",
       "278  SHAME_264.txt           2033             6.555337    4.156275\n",
       "279   SHAME_27.txt           5444             6.767818    4.882385\n",
       "280  SHAME_236.txt           4908             6.115322    4.781143\n",
       "\n",
       "[281 rows x 4 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = compute_sentence_length_stats_np('../data/lemma_txt_corpus/sentence', stopwords)\n",
    "df.to_csv('../output/avg_sent_length.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "16877191",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 326/326 [00:16<00:00, 19.26it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>txt_name</th>\n",
       "      <th>num_paragraphs</th>\n",
       "      <th>avg_paragraph_length</th>\n",
       "      <th>std_length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SHAME_92.txt</td>\n",
       "      <td>584</td>\n",
       "      <td>23.171233</td>\n",
       "      <td>38.613999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SHAME_242.txt</td>\n",
       "      <td>852</td>\n",
       "      <td>22.156103</td>\n",
       "      <td>25.511092</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>SHAME_136.txt</td>\n",
       "      <td>1339</td>\n",
       "      <td>21.616131</td>\n",
       "      <td>21.821101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>SHAME_204.txt</td>\n",
       "      <td>1044</td>\n",
       "      <td>19.812261</td>\n",
       "      <td>26.652719</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>SHAME_108.txt</td>\n",
       "      <td>609</td>\n",
       "      <td>19.091954</td>\n",
       "      <td>28.541949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>321</th>\n",
       "      <td>SHAME_40.txt</td>\n",
       "      <td>1785</td>\n",
       "      <td>18.274510</td>\n",
       "      <td>21.328383</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>322</th>\n",
       "      <td>SHAME_264.txt</td>\n",
       "      <td>858</td>\n",
       "      <td>18.413753</td>\n",
       "      <td>15.373761</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>323</th>\n",
       "      <td>SHAME_27.txt</td>\n",
       "      <td>2314</td>\n",
       "      <td>18.178911</td>\n",
       "      <td>23.161736</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>324</th>\n",
       "      <td>SHAME_68.txt</td>\n",
       "      <td>52</td>\n",
       "      <td>30.423077</td>\n",
       "      <td>28.863673</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>325</th>\n",
       "      <td>SHAME_236.txt</td>\n",
       "      <td>746</td>\n",
       "      <td>46.119303</td>\n",
       "      <td>49.650677</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>326 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          txt_name  num_paragraphs  avg_paragraph_length  std_length\n",
       "0     SHAME_92.txt             584             23.171233   38.613999\n",
       "1    SHAME_242.txt             852             22.156103   25.511092\n",
       "2    SHAME_136.txt            1339             21.616131   21.821101\n",
       "3    SHAME_204.txt            1044             19.812261   26.652719\n",
       "4    SHAME_108.txt             609             19.091954   28.541949\n",
       "..             ...             ...                   ...         ...\n",
       "321   SHAME_40.txt            1785             18.274510   21.328383\n",
       "322  SHAME_264.txt             858             18.413753   15.373761\n",
       "323   SHAME_27.txt            2314             18.178911   23.161736\n",
       "324   SHAME_68.txt              52             30.423077   28.863673\n",
       "325  SHAME_236.txt             746             46.119303   49.650677\n",
       "\n",
       "[326 rows x 4 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = compute_sentence_length_stats_np('../data/original_txt_corpus/paragraph', stopwords)\n",
    "df.to_csv('../output/avg_paragraph_length.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6522f4be",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "3.11.9",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
